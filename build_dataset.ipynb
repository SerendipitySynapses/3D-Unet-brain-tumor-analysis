{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import glob\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from tifffile import imsave\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import random\n",
    "\n",
    "# Initialize the MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Define dataset paths\n",
    "TRAIN_DATASET_PATH = './brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/'\n",
    "\n",
    "# Handling the renamed segmented file\n",
    "seg_file_path = TRAIN_DATASET_PATH + 'BraTS20_Training_355/W39_1998.09.19_Segm.nii'\n",
    "if os.path.exists(seg_file_path):\n",
    "    os.rename(seg_file_path, TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_seg.nii')\n",
    "\n",
    "# Load and preprocess sample images and masks\n",
    "# Load the FLAIR image\n",
    "test_image_flair = nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_flair.nii').get_fdata()\n",
    "# Scale the FLAIR image to [0, 1]\n",
    "test_image_flair = scaler.fit_transform(test_image_flair.reshape(-1, test_image_flair.shape[-1])).reshape(test_image_flair.shape)\n",
    "\n",
    "# Load the T1 image\n",
    "test_image_t1 = nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_t1.nii').get_fdata()\n",
    "# Scale the T1 image to [0, 1]\n",
    "test_image_t1 = scaler.fit_transform(test_image_t1.reshape(-1, test_image_t1.shape[-1])).reshape(test_image_t1.shape)\n",
    "\n",
    "# Load the T1ce image\n",
    "test_image_t1ce = nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_t1ce.nii').get_fdata()\n",
    "# Scale the T1ce image to [0, 1]\n",
    "test_image_t1ce = scaler.fit_transform(test_image_t1ce.reshape(-1, test_image_t1ce.shape[-1])).reshape(test_image_t1ce.shape)\n",
    "\n",
    "# Load the T2 image\n",
    "test_image_t2 = nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_t2.nii').get_fdata()\n",
    "# Scale the T2 image to [0, 1]\n",
    "test_image_t2 = scaler.fit_transform(test_image_t2.reshape(-1, test_image_t2.shape[-1])).reshape(test_image_t2.shape)\n",
    "\n",
    "# Load the segmentation mask\n",
    "test_mask = nib.load(TRAIN_DATASET_PATH + 'BraTS20_Training_355/BraTS20_Training_355_seg.nii').get_fdata()\n",
    "# Convert the mask to uint8\n",
    "test_mask = test_mask.astype(np.uint8)\n",
    "# Change mask pixel values from 4 to 3\n",
    "test_mask[test_mask == 4] = 3\n",
    "\n",
    "# Visualize the sample images and mask\n",
    "n_slice = random.randint(0, test_mask.shape[2])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(231)\n",
    "plt.imshow(test_image_flair[:, :, n_slice], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(232)\n",
    "plt.imshow(test_image_t1[:, :, n_slice], cmap='gray')\n",
    "plt.title('Image t1')\n",
    "plt.subplot(233)\n",
    "plt.imshow(test_image_t1ce[:, :, n_slice], cmap='gray')\n",
    "plt.title('Image t1ce')\n",
    "plt.subplot(234)\n",
    "plt.imshow(test_image_t2[:, :, n_slice], cmap='gray')\n",
    "plt.title('Image t2')\n",
    "plt.subplot(235)\n",
    "plt.imshow(test_mask[:, :, n_slice])\n",
    "plt.title('Mask')\n",
    "plt.show()\n",
    "\n",
    "# Combine images into a single multichannel image\n",
    "combined_x = np.stack([test_image_flair, test_image_t1ce, test_image_t2], axis=3)\n",
    "# Crop the images to a size divisible by 64\n",
    "combined_x = combined_x[56:184, 56:184, 13:141]\n",
    "\n",
    "# Crop the mask to match the image dimensions\n",
    "test_mask = test_mask[56:184, 56:184, 13:141]\n",
    "\n",
    "# Visualize the cropped images and mask\n",
    "n_slice = random.randint(0, test_mask.shape[2])\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.subplot(221)\n",
    "plt.imshow(combined_x[:, :, n_slice, 0], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(222)\n",
    "plt.imshow(combined_x[:, :, n_slice, 1], cmap='gray')\n",
    "plt.title('Image t1ce')\n",
    "plt.subplot(223)\n",
    "plt.imshow(combined_x[:, :, n_slice, 2], cmap='gray')\n",
    "plt.title('Image t2')\n",
    "plt.subplot(224)\n",
    "plt.imshow(test_mask[:, :, n_slice])\n",
    "plt.title('Mask')\n",
    "plt.show()\n",
    "\n",
    "# Save the combined images and mask\n",
    "imsave('BraTS2020_TrainingData/combined255.tif', combined_x)\n",
    "np.save('BraTS2020_TrainingData/combined255.npy', combined_x)\n",
    "\n",
    "# Load and convert the mask to categorical\n",
    "test_mask = to_categorical(test_mask, num_classes=4)\n",
    "\n",
    "# Process all images in the dataset\n",
    "t2_list = sorted(glob.glob(TRAIN_DATASET_PATH + '*/BraTS20_Training_*_t2.nii'))\n",
    "t1ce_list = sorted(glob.glob(TRAIN_DATASET_PATH + '*/BraTS20_Training_*_t1ce.nii'))\n",
    "flair_list = sorted(glob.glob(TRAIN_DATASET_PATH + '*/BraTS20_Training_*_flair.nii'))\n",
    "mask_list = sorted(glob.glob(TRAIN_DATASET_PATH + '*/BraTS20_Training_*_seg.nii'))\n",
    "\n",
    "for img in range(len(t2_list)):\n",
    "    print(\"Now preparing image and masks number:\", img)\n",
    "\n",
    "    # Load and preprocess T2 image\n",
    "    temp_image_t2 = nib.load(t2_list[img]).get_fdata()\n",
    "    temp_image_t2 = scaler.fit_transform(temp_image_t2.reshape(-1, temp_image_t2.shape[-1])).reshape(temp_image_t2.shape)\n",
    "\n",
    "    # Load and preprocess T1ce image\n",
    "    temp_image_t1ce = nib.load(t1ce_list[img]).get_fdata()\n",
    "    temp_image_t1ce = scaler.fit_transform(temp_image_t1ce.reshape(-1, temp_image_t1ce.shape[-1])).reshape(temp_image_t1ce.shape)\n",
    "\n",
    "    # Load and preprocess FLAIR image\n",
    "    temp_image_flair = nib.load(flair_list[img]).get_fdata()\n",
    "    temp_image_flair = scaler.fit_transform(temp_image_flair.reshape(-1, temp_image_flair.shape[-1])).reshape(temp_image_flair.shape)\n",
    "\n",
    "    # Load and preprocess mask\n",
    "    temp_mask = nib.load(mask_list[img]).get_fdata()\n",
    "    temp_mask = temp_mask.astype(np.uint8)\n",
    "    temp_mask[temp_mask == 4] = 3\n",
    "\n",
    "    # Combine images into a single multichannel image\n",
    "    temp_combined_images = np.stack([temp_image_flair, temp_image_t1ce, temp_image_t2], axis=3)\n",
    "    # Crop the images to a size divisible by 64\n",
    "    temp_combined_images = temp_combined_images[56:184, 56:184, 13:141]\n",
    "    # Crop the mask to match the image dimensions\n",
    "    temp_mask = temp_mask[56:184, 56:184, 13:141]\n",
    "\n",
    "    # Check if the volume has at least 1% useful labels\n",
    "    val, counts = np.unique(temp_mask, return_counts=True)\n",
    "    if (1 - (counts[0] / counts.sum())) > 0.01:\n",
    "        print(\"Save Me\")\n",
    "        temp_mask = to_categorical(temp_mask, num_classes=4)\n",
    "        np.save(TRAIN_DATASET_PATH + 'input_data_3channels/images/image_' + str(img) + '.npy', temp_combined_images)\n",
    "        np.save(TRAIN_DATASET_PATH + 'input_data_3channels/masks/mask_' + str(img) + '.npy', temp_mask)\n",
    "    else:\n",
    "        print(\"I am useless\")\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "import splitfolders\n",
    "\n",
    "input_folder = TRAIN_DATASET_PATH + 'input_data_3channels/'\n",
    "output_folder = TRAIN_DATASET_PATH + 'input_data_128/'\n",
    "splitfolders.ratio(input_folder, output=output_folder, seed=42, ratio=(.75, .25), group_prefix=None)\n"
   ],
   "id": "f79012422d78dc76"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "# Define function to load images from a directory\n",
    "def load_img(img_dir, img_list):\n",
    "    images = []\n",
    "    for i, image_name in enumerate(img_list):\n",
    "        if image_name.split('.')[1] == 'npy':\n",
    "            image = np.load(os.path.join(img_dir, image_name))\n",
    "            images.append(image)\n",
    "    images = np.array(images)\n",
    "    return images\n",
    "\n",
    "# Define custom data generator\n",
    "def imageLoader(img_dir, img_list, mask_dir, mask_list, batch_size):\n",
    "    L = len(img_list)\n",
    "    while True:  # Keras requires the generator to be infinite\n",
    "        batch_start = 0\n",
    "        batch_end = batch_size\n",
    "        while batch_start < L:\n",
    "            limit = min(batch_end, L)\n",
    "            X = load_img(img_dir, img_list[batch_start:limit])\n",
    "            Y = load_img(mask_dir, mask_list[batch_start:limit])\n",
    "            yield (X, Y)  # Yield a tuple of two numpy arrays with batch_size samples\n",
    "            batch_start += batch_size\n",
    "            batch_end += batch_size\n",
    "\n",
    "# Define dataset paths for training images and masks\n",
    "train_img_dir = \"./brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/input_data_128/train/images/\"\n",
    "train_mask_dir = \"./brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/input_data_128/train/masks/\"\n",
    "\n",
    "# Get list of all image and mask files\n",
    "train_img_list = os.listdir(train_img_dir)\n",
    "train_mask_list = os.listdir(train_mask_dir)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 2\n",
    "\n",
    "# Initialize the custom data generator\n",
    "train_img_datagen = imageLoader(train_img_dir, train_img_list, train_mask_dir, train_mask_list, batch_size)\n",
    "\n",
    "# Test the generator\n",
    "img, msk = train_img_datagen.__next__()\n",
    "\n",
    "# Randomly select an image and its corresponding mask from the batch\n",
    "img_num = random.randint(0, img.shape[0] - 1)\n",
    "test_img = img[img_num]\n",
    "test_mask = msk[img_num]\n",
    "\n",
    "# Convert mask from categorical to original labels\n",
    "test_mask = np.argmax(test_mask, axis=3)\n",
    "\n",
    "# Randomly select a slice to visualize\n",
    "n_slice = random.randint(0, test_mask.shape[2])\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Visualize the different channels of the selected image slice and its corresponding mask\n",
    "plt.subplot(221)\n",
    "plt.imshow(test_img[:, :, n_slice, 0], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(222)\n",
    "plt.imshow(test_img[:, :, n_slice, 1], cmap='gray')\n",
    "plt.title('Image t1ce')\n",
    "plt.subplot(223)\n",
    "plt.imshow(test_img[:, :, n_slice, 2], cmap='gray')\n",
    "plt.title('Image t2')\n",
    "plt.subplot(224)\n",
    "plt.imshow(test_mask[:, :, n_slice])\n",
    "plt.title('Mask')\n",
    "plt.show()\n"
   ],
   "id": "c4a613b9720141d9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
