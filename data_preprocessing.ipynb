{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-15T01:02:20.847223Z",
     "start_time": "2024-06-15T01:02:20.838955Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "def load_nifti_file(filepath):\n",
    "    \"\"\"Load a NIfTI file and return its data as a numpy array.\"\"\"\n",
    "    scan = nib.load(filepath)\n",
    "    return scan.get_fdata()\n",
    "\n",
    "def normalize(volume):\n",
    "    \"\"\"Normalize the volume by clipping and standardizing.\"\"\"\n",
    "    min_val = -1000\n",
    "    max_val = 400\n",
    "    volume = np.clip(volume, min_val, max_val)\n",
    "    mean = np.mean(volume)\n",
    "    std = np.std(volume)\n",
    "    volume = (volume - mean) / std\n",
    "    return volume\n",
    "\n",
    "path = {\n",
    "    'Training': {\n",
    "        'flair': 'flair',\n",
    "        't1': 't1',\n",
    "        't1ce': 't1ce',\n",
    "        't2': 't2',\n",
    "        'mask': 'seg'\n",
    "    },\n",
    "    # 'Validation': {\n",
    "    #     'flair': 'flair',\n",
    "    #     't1': 't1',\n",
    "    #     't1ce': 't1ce',\n",
    "    #     't2': 't2'\n",
    "    # }\n",
    "}\n",
    "data_dir = './Dataset'\n",
    "output_dir = './Dataset/Processed'\n",
    "def preprocess_data(data_dir, output_dir):\n",
    "    \"\"\"Load, preprocess and split the dataset based on the provided folder structure.\"\"\"\n",
    "    for phase, data in path.items():\n",
    "        if phase == 'Training':\n",
    "            for folder,modality in data.items():\n",
    "                npy_path=os.path.join(output_dir, phase, folder)\n",
    "                os.makedirs(npy_path, exist_ok=True)\n",
    "                for i in range(1,370):\n",
    "                    id=f\"{i:03d}\"\n",
    "                    file_name=f'BraTS20_{phase}_{id}_{modality}'\n",
    "                    folder_path = os.path.join(data_dir, phase, folder)\n",
    "                    img = load_nifti_file(os.path.join(folder_path, file_name+'.nii'))\n",
    "                    img = normalize(img)\n",
    "                    npy_file_path = os.path.join(npy_path, file_name + '.npy')\n",
    "                    np.save(npy_file_path,img)\n",
    "preprocess_data(data_dir, output_dir)"
   ],
   "id": "d7598744726b0b83",
   "execution_count": 193,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class CustomDataGen(tf.keras.utils.Sequence):\n",
    "    def __init__(self, image_filenames, labels, batch_size, image_size, augment=False):\n",
    "        self.image_filenames = image_filenames\n",
    "        self.labels = labels\n",
    "        self.batch_size = batch_size\n",
    "        self.image_size = image_size\n",
    "        self.augment = augment\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "        if self.augment:\n",
    "            self.augmenter = ImageDataGenerator(\n",
    "                rotation_range=10,\n",
    "                width_shift_range=0.1,\n",
    "                height_shift_range=0.1,\n",
    "                zoom_range=0.1,\n",
    "                horizontal_flip=True,\n",
    "                fill_mode='nearest'\n",
    "            )\n",
    "def __len__(self):\n",
    "    \"\"\"Denotes the number of batches per epoch.\"\"\"\n",
    "    return int(np.ceil(len(self.image_filenames) / self.batch_size))\n",
    "\n",
    "def on_epoch_end(self):\n",
    "    \"\"\"Updates indexes after each epoch.\"\"\"\n",
    "    self.indexes = np.arange(len(self.image_filenames))\n",
    "    if self.augment:\n",
    "        np.random.shuffle(self.indexes)\n",
    "\n",
    "def __getitem__(self, index):\n",
    "    \"\"\"Generate one batch of data.\"\"\"\n",
    "    batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "    batch_filenames = [self.image_filenames[i] for i in batch_indexes]\n",
    "    batch_labels = [self.labels[i] for i in batch_indexes]\n",
    "\n",
    "    X, y = self.__data_generation(batch_filenames, batch_labels)\n",
    "\n",
    "    if self.augment:\n",
    "        return next(self.augmenter.flow(X, y, batch_size=self.batch_size))\n",
    "    else:\n",
    "        return X, y\n",
    "\n",
    "def __data_generation(self, batch_filenames, batch_labels):\n",
    "    \"\"\"Generates data containing batch_size samples.\"\"\"\n",
    "    X = np.empty((self.batch_size, *self.image_size, 1))\n",
    "    y = np.empty((self.batch_size, *self.image_size, 1))\n",
    "\n",
    "    for i, (filename, label) in enumerate(zip(batch_filenames, batch_labels)):\n",
    "        # Load image and resize\n",
    "        image = np.load(filename)\n",
    "        image = np.expand_dims(image, axis=-1)\n",
    "        label = np.load(label)\n",
    "        label = np.expand_dims(label, axis=-1)\n",
    "        \n",
    "        X[i,] = image\n",
    "        y[i,] = label\n",
    "\n",
    "    return X, y\n"
   ],
   "id": "376e7378fb1883f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_file_paths(data_dir):\n",
    "    \"\"\"Get file paths for images and labels.\"\"\"\n",
    "    image_paths = []\n",
    "    label_paths = []\n",
    "    for root, _, files in os.walk(data_dir):\n",
    "        for file in files:\n",
    "            if 'flair' in file:\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "            elif 'seg' in file:\n",
    "                label_paths.append(os.path.join(root, file))\n",
    "    return sorted(image_paths), sorted(label_paths)\n"
   ],
   "id": "3418c487b364c0bf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_dir = './Dataset/Processed'\n",
    "image_size = (240, 240, 155)\n",
    "batch_size = 2\n",
    "epochs = 100\n",
    "\n",
    "train_image_paths, train_label_paths = get_file_paths(os.path.join(data_dir, 'train'))\n",
    "val_image_paths, val_label_paths = get_file_paths(os.path.join(data_dir, 'val'))\n",
    "\n",
    "train_gen = CustomDataGen(train_image_paths, train_label_paths, batch_size, image_size, augment=True)\n",
    "val_gen = CustomDataGen(val_image_paths, val_label_paths, batch_size, image_size, augment=False)\n"
   ],
   "id": "6450b3035eb96013",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, Concatenate, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def conv_block(inputs, num_filters):\n",
    "    \"\"\"Convolutional block consisting of two Conv3D layers followed by an activation function.\"\"\"\n",
    "    x = Conv3D(num_filters, 3, padding='same')(inputs)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv3D(num_filters, 3, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def encoder_block(inputs, num_filters):\n",
    "    \"\"\"Encoder block consisting of a conv block followed by a max pooling layer.\"\"\"\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(inputs, skip_features, num_filters):\n",
    "    \"\"\"Decoder block consisting of an upsampling layer followed by a conv block.\"\"\"\n",
    "    x = UpSampling3D(size=(2, 2, 2))(inputs)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "def unet_model(input_shape):\n",
    "    \"\"\"Builds the 3D U-Net model.\"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    s1, p1 = encoder_block(inputs, 32)\n",
    "    s2, p2 = encoder_block(p1, 64)\n",
    "    s3, p3 = encoder_block(p2, 128)\n",
    "    s4, p4 = encoder_block(p3, 256)\n",
    "\n",
    "    # Bridge\n",
    "    b1 = conv_block(p4, 512)\n",
    "\n",
    "    # Decoder\n",
    "    d1 = decoder_block(b1, s4, 256)\n",
    "    d2 = decoder_block(d1, s3, 128)\n",
    "    d3 = decoder_block(d2, s2, 64)\n",
    "    d4 = decoder_block(d3, s1, 32)\n",
    "\n",
    "    outputs = Conv3D(1, 1, padding='same', activation='sigmoid')(d4)\n",
    "\n",
    "    model = Model(inputs, outputs, name='3d_unet')\n",
    "    return model\n"
   ],
   "id": "16af92ad471ac3c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model = unet_model(input_shape=(*image_size, 1))",
   "id": "afc8bc95b8a61e69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('unet_brats2020.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
    "\n",
    "history = model.fit(train_gen, validation_data=val_gen, epochs=epochs, callbacks=[checkpoint, early_stopping])\n"
   ],
   "id": "6f6f5c2417e607ab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "model.save_weights('model_weights.h5')",
   "id": "ddff5da699209204",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "833d3b79479ab9ab",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
