{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import glob\n",
    "import random\n",
    "import keras\n",
    "from keras.metrics import MeanIoU\n",
    "import segmentation_models_3D as sm\n",
    "from custom_datagen import imageLoader\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv3D, MaxPooling3D, concatenate, Conv3DTranspose, BatchNormalization, Dropout, Lambda\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Initialize the kernel initializer\n",
    "kernel_initializer = 'he_uniform'\n",
    "\n",
    "def simple_unet_model(IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS, num_classes):\n",
    "    \"\"\"\n",
    "    Define a simple 3D U-Net model.\n",
    "    \"\"\"\n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_DEPTH, IMG_CHANNELS))\n",
    "    s = inputs\n",
    "\n",
    "    # Contraction path\n",
    "    c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(s)\n",
    "    c1 = Dropout(0.1)(c1)\n",
    "    c1 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c1)\n",
    "    p1 = MaxPooling3D((2, 2, 2))(c1)\n",
    "    \n",
    "    c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p1)\n",
    "    c2 = Dropout(0.1)(c2)\n",
    "    c2 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c2)\n",
    "    p2 = MaxPooling3D((2, 2, 2))(c2)\n",
    "     \n",
    "    c3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p2)\n",
    "    c3 = Dropout(0.2)(c3)\n",
    "    c3 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c3)\n",
    "    p3 = MaxPooling3D((2, 2, 2))(c3)\n",
    "     \n",
    "    c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p3)\n",
    "    c4 = Dropout(0.2)(c4)\n",
    "    c4 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c4)\n",
    "    p4 = MaxPooling3D(pool_size=(2, 2, 2))(c4)\n",
    "     \n",
    "    c5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(p4)\n",
    "    c5 = Dropout(0.3)(c5)\n",
    "    c5 = Conv3D(256, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c5)\n",
    "    \n",
    "    # Expansive path \n",
    "    u6 = Conv3DTranspose(128, (2, 2, 2), strides=(2, 2, 2), padding='same')(c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u6)\n",
    "    c6 = Dropout(0.2)(c6)\n",
    "    c6 = Conv3D(128, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c6)\n",
    "     \n",
    "    u7 = Conv3DTranspose(64, (2, 2, 2), strides=(2, 2, 2), padding='same')(c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u7)\n",
    "    c7 = Dropout(0.2)(c7)\n",
    "    c7 = Conv3D(64, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c7)\n",
    "     \n",
    "    u8 = Conv3DTranspose(32, (2, 2, 2), strides=(2, 2, 2), padding='same')(c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u8)\n",
    "    c8 = Dropout(0.1)(c8)\n",
    "    c8 = Conv3D(32, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c8)\n",
    "     \n",
    "    u9 = Conv3DTranspose(16, (2, 2, 2), strides=(2, 2, 2), padding='same')(c8)\n",
    "    u9 = concatenate([u9, c1])\n",
    "    c9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(u9)\n",
    "    c9 = Dropout(0.1)(c9)\n",
    "    c9 = Conv3D(16, (3, 3, 3), activation='relu', kernel_initializer=kernel_initializer, padding='same')(c9)\n",
    "     \n",
    "    outputs = Conv3D(num_classes, (1, 1, 1), activation='softmax')(c9)\n",
    "     \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Paths to training and validation image and mask directories\n",
    "train_img_dir = \"./brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/input_data_128/train/images/\"\n",
    "train_mask_dir = \"./brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/input_data_128/train/masks/\"\n",
    "val_img_dir = \"./brats20-dataset-training-validation/BraTS2020_ValidationData/input_data_128/val/images/\"\n",
    "val_mask_dir = \"./brats20-dataset-training-validation/BraTS2020_ValidationData/input_data_128/val/masks/\"\n",
    "\n",
    "# Get list of image and mask files\n",
    "train_img_list = os.listdir(train_img_dir)\n",
    "train_mask_list = os.listdir(train_mask_dir)\n",
    "val_img_list = os.listdir(val_img_dir)\n",
    "val_mask_list = os.listdir(val_mask_dir)\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 2\n",
    "\n",
    "# Initialize the custom data generator\n",
    "train_img_datagen = imageLoader(train_img_dir, train_img_list, train_mask_dir, train_mask_list, batch_size)\n",
    "val_img_datagen = imageLoader(val_img_dir, val_img_list, val_mask_dir, val_mask_list, batch_size)\n",
    "\n",
    "# Verify the generator\n",
    "img, msk = train_img_datagen.__next__()\n",
    "\n",
    "# Randomly select an image and its corresponding mask from the batch\n",
    "img_num = random.randint(0, img.shape[0] - 1)\n",
    "test_img = img[img_num]\n",
    "test_mask = msk[img_num]\n",
    "test_mask = np.argmax(test_mask, axis=3)\n",
    "\n",
    "# Randomly select a slice to visualize\n",
    "n_slice = random.randint(0, test_mask.shape[2])\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Visualize the different channels of the selected image slice and its corresponding mask\n",
    "plt.subplot(221)\n",
    "plt.imshow(test_img[:, :, n_slice, 0], cmap='gray')\n",
    "plt.title('Image flair')\n",
    "plt.subplot(222)\n",
    "plt.imshow(test_img[:, :, n_slice, 1], cmap='gray')\n",
    "plt.title('Image t1ce')\n",
    "plt.subplot(223)\n",
    "plt.imshow(test_img[:, :, n_slice, 2], cmap='gray')\n",
    "plt.title('Image t2')\n",
    "plt.subplot(224)\n",
    "plt.imshow(test_mask[:, :, n_slice])\n",
    "plt.title('Mask')\n",
    "plt.show()\n",
    "\n",
    "# Define loss, metrics, and optimizer\n",
    "wt0, wt1, wt2, wt3 = 0.25, 0.25, 0.25, 0.25  # Use equal weights for now\n",
    "dice_loss = sm.losses.DiceLoss(class_weights=np.array([wt0, wt1, wt2, wt3]))\n",
    "focal_loss = sm.losses.CategoricalFocalLoss()\n",
    "total_loss = dice_loss + (1 * focal_loss)\n",
    "metrics = ['accuracy', sm.metrics.IOUScore(threshold=0.5)]\n",
    "LR = 0.0001\n",
    "optim = keras.optimizers.Adam(LR)\n",
    "\n",
    "# Fit the model\n",
    "steps_per_epoch = len(train_img_list) // batch_size\n",
    "val_steps_per_epoch = len(val_img_list) // batch_size\n",
    "\n",
    "model = simple_unet_model(IMG_HEIGHT=128, IMG_WIDTH=128, IMG_DEPTH=128, IMG_CHANNELS=3, num_classes=4)\n",
    "model.compile(optimizer=optim, loss=total_loss, metrics=metrics)\n",
    "print(model.summary())\n",
    "print(model.input_shape)\n",
    "print(model.output_shape)\n",
    "\n",
    "history = model.fit(train_img_datagen,\n",
    "                    steps_per_epoch=steps_per_epoch,\n",
    "                    epochs=100,\n",
    "                    verbose=1,\n",
    "                    validation_data=val_img_datagen,\n",
    "                    validation_steps=val_steps_per_epoch)\n",
    "\n",
    "model.save('brats_3d.hdf5')\n",
    "\n",
    "# Plot the training and validation loss and accuracy\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "plt.plot(epochs, acc, 'y', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Load the model for prediction or continued training\n",
    "my_model = load_model('brats_3d.hdf5', custom_objects={\n",
    "                      'dice_loss_plus_1focal_loss': total_loss, 'iou_score': sm.metrics.IOUScore(threshold=0.5)})\n",
    "\n",
    "# Continue training\n",
    "history2 = my_model.fit(train_img_datagen,\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        epochs=1,\n",
    "                        verbose=1,\n",
    "                        validation_data=val_img_datagen,\n",
    "                        validation_steps=val_steps_per_epoch)\n",
    "\n",
    "# For predictions without recompiling\n",
    "my_model = load_model('brats_3d.hdf5', compile=False)\n",
    "\n",
    "# Verify IoU on a batch of images from the test dataset\n",
    "batch_size = 8\n",
    "test_img_datagen = imageLoader(val_img_dir, val_img_list, val_mask_dir, val_mask_list, batch_size)\n",
    "test_image_batch, test_mask_batch = test_img_datagen.__next__()\n",
    "\n",
    "test_mask_batch_argmax = np.argmax(test_mask_batch, axis=4)\n",
    "test_pred_batch = my_model.predict(test_image_batch)\n",
    "test_pred_batch_argmax = np.argmax(test_pred_batch, axis=4)\n",
    "\n",
    "IOU_keras = MeanIoU(num_classes=4)\n",
    "IOU_keras.update_state(test_pred_batch_argmax, test_mask_batch_argmax)\n",
    "print(\"Mean IoU =\", IOU_keras.result().numpy())\n",
    "\n",
    "# Predict on a single test image\n",
    "img_num = 82\n",
    "test_img = np.load(val_img_dir + \"image_\" + str(img_num) + \".npy\")\n",
    "test_mask = np.load(val_mask_dir + \"mask_\" + str(img_num) + \".npy\")\n",
    "test_mask_argmax = np.argmax(test_mask, axis=3)\n",
    "\n",
    "test_img_input = np.expand_dims(test_img, axis=0)\n",
    "test_prediction = my_model.predict(test_img_input)\n",
    "test_prediction_argmax = np.argmax(test_prediction, axis=4)[0, :, :, :]\n",
    "\n",
    "# Plot individual slices from test predictions for verification\n",
    "n_slice = 55\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.subplot(231)\n",
    "plt.title('Testing Image')\n",
    "plt.imshow(test_img[:, :, n_slice, 1], cmap='gray')\n",
    "plt.subplot(232)\n",
    "plt.title('Testing Label')\n",
    "plt.imshow(test_mask_argmax[:, :, n_slice])\n",
    "plt.subplot(233)\n",
    "plt.title('Prediction on test image')\n",
    "plt.imshow(test_prediction_argmax[:, :, n_slice])\n",
    "plt.show()\n"
   ],
   "id": "3c6740245a6121c7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
