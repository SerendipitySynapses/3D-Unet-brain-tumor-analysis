{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:19:01.199939Z",
     "start_time": "2024-06-17T09:19:01.175513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Dataset\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "def load_nifti_file(filepath):\n",
    "    #Load a NIfTI file and return its data as a numpy array\n",
    "    scan = nib.load(filepath)\n",
    "    return scan.get_fdata()\n",
    "\n",
    "def normalize(volume):\n",
    "    #Normalize the volume by clipping and standardizing\n",
    "    min_val = -1000\n",
    "    max_val = 400\n",
    "    volume = np.clip(volume, min_val, max_val)\n",
    "    mean = np.mean(volume)\n",
    "    std = np.std(volume)\n",
    "    volume = (volume - mean) / std\n",
    "    return volume\n",
    "\n",
    "input_dir = './Dataset'\n",
    "output_dir = './Dataset/Processed'\n",
    "total_size={'Training':369,'Validation':125}\n",
    "\n",
    "input={'Training':['flair', 't1', 't1ce', 't2','seg'],\n",
    " 'Validation':['flair', 't1', 't1ce', 't2']}\n",
    "def Datagen(phase,chunk_index,chunk_size,input_dir, output_dir):\n",
    "        chunk_size=chunk_size\n",
    "        X = np.empty([chunk_size, 240, 240, 155,4])\n",
    "        y = np.empty([chunk_size,240, 240, 155,1], dtype=int)\n",
    "        start_id = chunk_index * chunk_size + 1\n",
    "        end_id = min((chunk_index + 1) * chunk_size, total_size[phase])\n",
    "        for i in range(start_id, end_id + 1):\n",
    "            h=0\n",
    "            id = f\"{i:03d}\"\n",
    "            npy_folder_path = os.path.join(output_dir, phase, f'chunk_{chunk_index}',id)\n",
    "            os.makedirs(npy_folder_path, exist_ok=True)\n",
    "            for j,modality in enumerate( input[phase]):\n",
    "                if modality != 'seg':\n",
    "                    #Modality data\n",
    "                    channel_name = f'BraTS20_{phase}_{id}_{modality}'\n",
    "                    channel_path = os.path.join(input_dir, phase, modality)\n",
    "                    channel = load_nifti_file(os.path.join(channel_path, channel_name+ '.nii'))\n",
    "                    # Normalize \n",
    "                    channel = normalize(channel)\n",
    "                    # Save numpy file\n",
    "                    npy_channel_file_path=os.path.join(npy_folder_path,channel_name+ '.npy')\n",
    "                    np.save(npy_channel_file_path, channel)\n",
    "                    X[h, :, :, :, j] = np.load(os.path.join(npy_folder_path,channel_name+ '.npy'))\n",
    "                else:\n",
    "                    #Mask data\n",
    "                    mask_path= os.path.join(input_dir, phase, 'mask')\n",
    "                    mask_name= f'BraTS20_{phase}_{id}_{modality}'\n",
    "                    mask = load_nifti_file(os.path.join(mask_path, mask_name + '.nii'))\n",
    "                    npy_mask_file_path = os.path.join(npy_folder_path, mask_name + '.npy')\n",
    "                    np.save(npy_mask_file_path, mask)\n",
    "                    npy_mask=np.load(os.path.join(npy_folder_path, mask_name + '.npy'))\n",
    "                    y[h,] = npy_mask.reshape((240, 240, 155, 1))\n",
    "            h=+1\n",
    "        if phase=='Training':\n",
    "            return X, y\n",
    "        else:\n",
    "            return X"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 129
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-17T09:19:16.531310Z",
     "start_time": "2024-06-17T09:19:08.263606Z"
    }
   },
   "cell_type": "code",
   "source": "X_train, y_train = Datagen(phase='Training', chunk_index=0, chunk_size=10, input_dir=input_dir, output_dir=output_dir)",
   "id": "1ae3301d0889c51d",
   "outputs": [],
   "execution_count": 130
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": 131,
   "source": "X_val = Datagen(phase='Validation', chunk_index=0, chunk_size=10, input_dir=input_dir, output_dir=output_dir)",
   "id": "1925a2fb944a33a7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Model Artichecture\n",
   "id": "4cf94961b75b92d7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Train ",
   "id": "60ca549c22527a10"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# Evaluate",
   "id": "f66add214aeedee8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv3D, MaxPooling3D, UpSampling3D, Concatenate, Activation\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def conv_block(inputs, num_filters):\n",
    "    \"\"\"Convolutional block consisting of two Conv3D layers followed by an activation function.\"\"\"\n",
    "    x = Conv3D(num_filters, 3, padding='same')(inputs)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv3D(num_filters, 3, padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def encoder_block(inputs, num_filters):\n",
    "    \"\"\"Encoder block consisting of a conv block followed by a max pooling layer.\"\"\"\n",
    "    x = conv_block(inputs, num_filters)\n",
    "    p = MaxPooling3D(pool_size=(2, 2, 2))(x)\n",
    "    return x, p\n",
    "\n",
    "def decoder_block(inputs, skip_features, num_filters):\n",
    "    \"\"\"Decoder block consisting of an upsampling layer followed by a conv block.\"\"\"\n",
    "    x = UpSampling3D(size=(2, 2, 2))(inputs)\n",
    "    x = Concatenate()([x, skip_features])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x\n",
    "def unet_model(input_shape):\n",
    "    \"\"\"Builds the 3D U-Net model.\"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    s1, p1 = encoder_block(inputs, 32)\n",
    "    s2, p2 = encoder_block(p1, 64)\n",
    "    s3, p3 = encoder_block(p2, 128)\n",
    "    s4, p4 = encoder_block(p3, 256)\n",
    "\n",
    "    # Bridge\n",
    "    b1 = conv_block(p4, 512)\n",
    "\n",
    "    # Decoder\n",
    "    d1 = decoder_block(b1, s4, 256)\n",
    "    d2 = decoder_block(d1, s3, 128)\n",
    "    d3 = decoder_block(d2, s2, 64)\n",
    "    d4 = decoder_block(d3, s1, 32)\n",
    "\n",
    "    outputs = Conv3D(1, 1, padding='same', activation='sigmoid')(d4)\n",
    "\n",
    "    model = Model(inputs, outputs, name='3d_unet')\n",
    "    return model\n",
    "model = unet_model(input_shape=(*image_size, 1))\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('unet_brats2020.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, mode='min')\n",
    "\n",
    "history = model.fit(train_gen, validation_data=val_gen, epochs=epochs, callbacks=[checkpoint, early_stopping])\n",
    "model.save_weights('model_weights.h5')"
   ],
   "id": "89fd4675dae8092f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d7fc3c24837c87e0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "45e42e4fd7fc9e40",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "54522a59d7c15f9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "2da371b94df474a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4eec6917d585c8af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "6a9b88752cdfe168",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "77eafc516bc1bd5b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "3890a57204b123b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "70aa3044daaec4e7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1888d172902fc020",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Iterate over each chunk\n",
    "for start in range(1, total_files + 1, chunk_size):\n",
    "    Datagen(phase='Training', chunk_index=start, chunk_size=chunk_size, input_dir=input_dir, output_dir=output_dir)\n",
    "    end = min(start_id + chunk_size - 1, total_files)"
   ],
   "id": "80f9a17e47e011a7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
